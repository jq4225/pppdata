---
title: "descriptives"
output: html_document
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(readxl)
library(bizdays)

# Note that this isn't relevant for Gov 50 at all: this is for my other
# projects where I needed to make a bunch of descriptive statistics
# for  everything in the regressions, so feel free to ignore this file entirely.
# This is NOT part of my Gov 50 final project (though the final tables
# end up being so)

loan_only <- readRDS('ppp_all_loans_withstate.rds')

#most_recent <- ppp_allvars_1027_crime
  #readRDS('ppp_allvars_1105.rds')

cal <-  create.calendar(name = "mycal", weekdays=c("saturday", "sunday"))

# Generally, the methodology is just to merge in my data sources one at a 
# time to the original dataset so I can get a true dataset average of 
# things like race, income and compare it to my sample to make sure
# we haven't egregiously selected for weird points.

```

```{r}
loan_only %>%
  mutate(business_days = bizdays(as.Date("2020-04-03"), date_approved, 
                                 'mycal')) %>%
  summarize(n = n(),
            mean = mean(business_days),
            std = sd(business_days))

loan_only %>% 
  mutate(delay = ifelse(date_approved > as.Date("2020-04-16"), 1, 0)) %>%
  summarize(mean = mean(delay), std = sd(delay))

most_recent %>%
    summarize(n = n(),
            mean = mean(business_days),
            std = sd(business_days))

most_recent %>%
  summarize(n = n(), mean = mean(delay), sd = sd(delay))
```


```{r}
ppp_150 <- read_csv("raw_data/sba/PPP_SBA_150.csv") %>%
  clean_names() %>%
  select(loan_range, zip, date_approved, lender, address, city, state,
         jobs_reported) %>%
  drop_na(zip, jobs_reported) %>%
  
  # This calculates the date on which loans were approved vs. when apps opened.
  
  mutate(date_approved = mdy(date_approved), 
         days_to_approval = date_approved - mdy("04/03/2020"),
         zip = as.character(zip))
```



```{r}
# Calculates mean for everything

sapply(most_recent, mean) %>%
  bind_rows() %>%
  pivot_longer(cols = zip:renter_percent, names_to = "variable", 
               values_to = "mean")
```

```{r}
# SD for everything

most_recent <- most_recent %>%
  select(business_days, median_family_income, minority_percent,
         high_school_pct, married_percent, male_percent, cook_pvi,
         rural, estimate_gini_index, violent_crime_rate, delay,
         loan_150_less, loan_150_350, loan_350_1mil, loan_1mil_2mil,
         loan_2mil_5mil, loan_5mil_10mil, jobs_reported, banks_per_pop,
         businesses_per_pop, payroll, unemployment_rate_apr, 
         unemployment_rate, mean_start_cases_weighted, 
         mean_start_deaths_weighted,
         mean_end_cases_weighted, mean_end_deaths_weighted, stay_at_home_apr,
         stay_at_home_current, non_essential_closure_apr, 
         non_essential_closure_current, renter_percent)


sapply(most_recent, sd) %>%
    bind_rows() %>%
  pivot_longer(cols = business_days:renter_percent, 
               names_to = "variable", values_to = "mean")
```

```{r}
# The following files read in the data sources one by one and then merge them
# so we lose the least data possible, then take averages. This is what takes
# up all the space. You can find most of the identical code and comments
# in file 1-4. 

acs_income <- 
  read_csv("raw_data/acs_income/ACSST5Y2018.S1903_data_with_overlays_2020-10-12T102624.csv",
                       skip = 1) %>%
  clean_names() %>%
  select(id, geographic_area_name, 
         estimate_median_income_dollars_families_families) %>%
  mutate(geographic_area_name = map_chr(geographic_area_name, ~ substring(., 6)),
         estimate_median_income_dollars_families_families = 
           as.double(estimate_median_income_dollars_families_families)) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

ppptemp <- left_join(loan_only, acs_income, 
                     by = c("zip" = "geographic_area_name")) %>%
  drop_na(estimate_median_income_dollars_families_families)

ppptemp %>%
  summarize(mean = mean(estimate_median_income_dollars_families_families),
            sd = sd(estimate_median_income_dollars_families_families))
```


```{r}
pop <- read_csv("raw_data/acs_pop/ACSDT5Y2018.B01003_data_with_overlays_2020-10-06T100104.csv",
                skip = 1) %>%
  clean_names() %>%
  mutate(geographic_area_name = 
           map_chr(geographic_area_name, ~ substring(., 6))) %>%
  select(-margin_of_error_total) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

banks <- read_csv("raw_data/fdic/OFFICES2_PART2.csv", col_types = cols(
  'ZIP' = col_character()))%>%
  clean_names() %>%
  select(zip) %>%
  filter(zip != 0) %>%
  
  # FDIC data drops leading zeroes from zip codes, so we add them back!
  
  mutate(zip = str_pad(zip, width = 5, "left", "0")) %>%
  mutate(zip = str_trim(zip, side = "both")) %>%
  group_by(zip) %>%
  summarize(number = n(), .groups = "drop")

ppp_pop <- left_join(loan_only, pop, by = c("zip" = "geographic_area_name")) %>%
  drop_na(estimate_total) %>%
  filter(estimate_total != 0)

temp2 <- left_join(ppp_pop, banks, by = "zip") %>%
  drop_na(number) %>%
  mutate(number = number * 10000/estimate_total)

temp2 %>%
  summarize(banks = n(), mean = mean(number), sd = sd(number))
```


```{r}
race <- read_csv("raw_data/acs_race/ACSDP5Y2018.DP05_data_with_overlays_2020-10-12T162449.csv",
                skip = 1) %>%
  clean_names() %>%
  select(geographic_area_name,percent_estimate_race_total_population_one_race_white,
         percent_estimate_race_total_population_one_race_black_or_african_american) %>%
  mutate(geographic_area_name = map_chr(geographic_area_name, ~ substring(., 6)),
         percent_estimate_race_total_population_one_race_white = 
           as.double(percent_estimate_race_total_population_one_race_white),
         percent_estimate_race_total_population_one_race_black_or_african_american = 
           as.double(percent_estimate_race_total_population_one_race_black_or_african_american)) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

temp3 <- left_join(loan_only, race, by = c("zip" = "geographic_area_name"))

temp3 %>%
  drop_na(percent_estimate_race_total_population_one_race_black_or_african_american,
          percent_estimate_race_total_population_one_race_white) %>%
  summarize(number = n(), 
            mean1 = mean(percent_estimate_race_total_population_one_race_black_or_african_american),
            sd1 = sd(percent_estimate_race_total_population_one_race_black_or_african_american),
            mean2 = mean(percent_estimate_race_total_population_one_race_white),
            sd2 = sd(percent_estimate_race_total_population_one_race_white))
```


```{r}

# Merging in education data

educ <- read_csv("raw_data/acs_educ/ACSST5Y2018.S1501_data_with_overlays_2020-10-15T084511.csv",
                 skip = 1) %>%
  clean_names() %>%
  mutate(geographic_area_name = map_chr(geographic_area_name, ~ substring(., 6)))

hs_educ <- educ %>%
  select(id, geographic_area_name, 
         estimate_percent_population_25_years_and_over_population_35_to_44_years_high_school_graduate_or_higher) %>%
  rename(high_school_pct = 
           estimate_percent_population_25_years_and_over_population_35_to_44_years_high_school_graduate_or_higher) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

temp4 <- left_join(loan_only, hs_educ, by = c("zip" = "geographic_area_name")) %>%
  drop_na(high_school_pct)

temp4 %>%
  mutate(high_school_pct = as.double(high_school_pct)) %>%
  drop_na(high_school_pct) %>%
  summarize(number = n(), mean = mean(high_school_pct),
            sd = sd(high_school_pct))
```
```{r}

# Merging in loan dummies

zip_data_with_dummies <- loan_only %>%
  mutate("350_1mil" = ifelse(loan_range == "d $350,000-1 million", 1, 0),
         "150-350" = ifelse(loan_range == "e $150,000-350,000", 1, 0),
         "5mil_10mil" = ifelse(loan_range == "a $5-10 million", 1, 0),
         "2mil_5mil" = ifelse(loan_range == "b $2-5 million", 1, 0),
         "1mil_2mil" = ifelse(loan_range == "c $1-2 million", 1, 0),
         "150_less" = ifelse(loan_range == "less than 150k", 1, 0)
         ) %>%
    rename(loan_350_1mil = "350_1mil", loan_150_350 = "150-350",
         loan_5mil_10mil = "5mil_10mil", loan_2mil_5mil = "2mil_5mil",
         loan_1mil_2mil = "1mil_2mil", loan_150_less = "150_less")

zip_data_with_dummies %>%
  summarize(mean_150 = mean(loan_150_less),
            sd_150 = sd(loan_150_less),
            mean_150_350 = mean(loan_150_350),
            sd_150_350 = sd(loan_150_350),
            mean_350_1 = mean(loan_350_1mil),
            sd_350_1 = sd(loan_350_1mil),
            mean_1_2 = mean(loan_1mil_2mil),
            sd_1_2 = sd(loan_1mil_2mil),
            mean_2_5 = mean(loan_2mil_5mil),
            sd_2_5 = sd(loan_2mil_5mil),
            mean_5_10 = mean(loan_5mil_10mil),
            sd_5_10 = sd(loan_5mil_10mil))

```
```{r}

# Merging in congressional districts for cook pvi

zip_cd_crosswalk <- read_csv("raw_data/crosswalks/zcta_cd_actual_umiss.csv", skip = 1) %>%
  clean_names() %>%
  mutate(x116th_congressional_district = 
           ifelse(x116th_congressional_district == "00",
                    "AL", x116th_congressional_district)) %>%
  mutate(cd_name = 
           str_c(state_abbreviation, 
                 x116th_congressional_district, sep = "-")) %>%
  select(-state_code, -population_2010) %>%
  group_by(zip_census_tabulation_area) %>%
  
  # de-duplicate by assigning zips to only the CD where most of them are in
  
  arrange(cd116_to_zcta5_allocation_factor) %>%
  mutate(zip_census_tabulation_area = 
           str_pad(zip_census_tabulation_area, width = 5, "left", "0")) %>%
  slice(1)

cook_pvi <- read_csv(file = 'raw_data/cook_pvi/data-5vPn3.csv') %>%
  clean_names() %>%
  mutate(pvi_split = str_split(pvi, pattern = "\\+")) %>%
  unnest(pvi_split) %>%
  group_by(dist) %>%
  mutate(col = seq_along(dist)) %>%
  spread(key = col, value = pvi_split) %>%
  rename(party = "1", pct = "2") %>%
  mutate(pct = as.double(pct), dem_indicator = ifelse(party == "D", -1, 1)) %>%
  mutate(pct = pct * dem_indicator) %>%
  select(dist, party, pct)

zip_pvi <- left_join(zip_cd_crosswalk, cook_pvi, by = c("cd_name" = "dist")) %>%
  drop_na(pct) %>%
  select(zip_census_tabulation_area, cd_name, pct) %>%
  mutate(zip_census_tabulation_area = as.character(zip_census_tabulation_area))

temp5 <- left_join(loan_only, zip_pvi, 
                   by = c("zip" = "zip_census_tabulation_area")) %>%
  drop_na(pct)

temp5 %>%
  summarize(n = n(), mean = mean(pct), sd = sd(pct))
```
```{r}

# Adding in COVID cases and deaths, creating the estimates -- all identical
# to file 5 and 4 I think.

county_zip_crosswalk <- 
  read_excel('raw_data/crosswalks/COUNTY_ZIP_092020.xlsx') %>%
  clean_names() %>%
  select(county, zip, res_ratio)

county_covid <- read_csv('raw_data/covid/us-counties.csv') %>%
  filter(date > as.Date("2020-03-27")) %>%
  select(-county, -state)

weighted_cases1 <- left_join(county_zip_crosswalk, county_covid, 
                             by = c("county" = "fips")) %>%
  filter(date %in% c(as.Date("2020-04-03"), as.Date("2020-03-27"))) %>%
  group_by(zip) %>%
  mutate(mean_cases_app_start = (max(cases) - min(cases)) / 7, 
         mean_deaths_app_start = (max(deaths) - min(deaths)) / 7) %>%
  select(-cases, -deaths, -date) %>%
  distinct() %>%
  
  # To convert to zip code numbers we multiply by residential ratios
  # of each zip code per county, meaning we get an estimated # of deaths
  # assuming that deaths are equally distributed based on population.
  
  mutate(mean_start_cases_weighted = mean_cases_app_start * res_ratio,
         mean_start_deaths_weighted = mean_deaths_app_start * res_ratio) %>%
  select(-mean_cases_app_start, -mean_deaths_app_start) %>%
  mutate(mean_start_cases_weighted = sum(mean_start_cases_weighted),
         mean_start_deaths_weighted = sum(mean_start_deaths_weighted)) %>%
  select(-county, -res_ratio) %>%
  distinct()

temp6 <- left_join(ppp_pop, weighted_cases1, by = "zip") %>%
  drop_na(mean_start_cases_weighted, mean_start_deaths_weighted) %>%
  mutate(mean_start_cases_weighted = 
           mean_start_cases_weighted * 100000 / estimate_total,
         mean_start_deaths_weighted = 
           mean_start_deaths_weighted * 100000 / estimate_total)

temp6 %>%
  summarize(n = n(), mean1 = mean(mean_start_cases_weighted),
            sd1 = sd(mean_start_cases_weighted),
            mean2 = mean(mean_start_deaths_weighted),
            sd2 = sd(mean_start_deaths_weighted))

```
```{r}

# Manually collected bank lending policy data.

bank_ppp_policy_manual <- read_excel('raw_data/bank_ppp_policy_manual.xlsx', 
                                     sheet = "Sheet2") %>%
  mutate(sba_name = tolower(sba_name)) %>%
  mutate(sba_name = str_trim(sba_name, side = "both")) %>%
  drop_na(preference, requirement)

ppp_setup <- loan_only %>%
  mutate(lender = str_trim(lender, side = "both"), lender = tolower(lender))


# This is explained in file 4. We can just assign credit unions dummies
# b/c they only really lend to members anyway

temp7 <- left_join(ppp_setup, bank_ppp_policy_manual,
                                      by = c("lender" = "sba_name")) %>%
  mutate(requirement = 
           ifelse(str_detect(lender, pattern = "\\sfcu$"), 1, requirement),
         requirement = 
           ifelse(str_detect(lender, pattern = "\\scu$"), 1, requirement),
         requirement = 
           ifelse(str_detect(lender, pattern = "credit union"), 1, 
                  requirement)) %>%
  drop_na(requirement) %>%
  mutate(preference = replace_na(preference, 0))

temp7 %>%
  summarize(n = n(), mean1 = mean(preference), sd1 = sd(preference),
         mean2 = mean(requirement), sd2 = sd(requirement))
```


```{r}

# Adding in loans issued per bank

loan_numbers <- loan_only %>%
  select(lender) %>%
  group_by(lender) %>%
  summarize(bank_ppp_issued = n(), .groups = "drop")

temp8 <- left_join(loan_only, loan_numbers, by = "lender") %>%
  
  # rename("cook_pvi" = "pct", 
  #        "black_percent" = "percent_estimate_race_total_population_one_race_black_or_african_american",
  #        "white_percent" = "percent_estimate_race_total_population_one_race_white",
  #        "median_family_income" = "estimate_median_income_dollars_families_families",
  #        "population" = "estimate_total") %>%
  
  select(-loan_range)

temp8 %>%
  drop_na(bank_ppp_issued) %>%
  summarize(n = n(), mean = mean(bank_ppp_issued), sd = sd(bank_ppp_issued))
```

```{r}

# Rurality descriptives

rural <- read_excel("raw_data/crosswalks/forhp-eligible-zips.xlsx") %>%
  clean_names() %>%
  select(-state) %>%
  mutate(rural = 1)

temp9 <- left_join(loan_only, rural, by = "zip") %>%
  mutate(rural = replace_na(rural, 0)) %>%
  mutate(rural = as.double(rural))

temp9 %>%
  summarize(mean = mean(rural), sd = sd(rural))
```
```{r}

# Business count descriptives

biz_count <- read_csv("raw_data/acs_business/ZBP2014.CB1400ZBP_data_with_overlays_2020-10-19T095307.csv",
                      skip = 1) %>%
  clean_names()  %>%
  mutate(geographic_area_name = substring(geographic_area_name, 5, 9)) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both")) %>%
  filter(meaning_of_2012_naics_code == "Total for all sectors") %>%
  select(geographic_area_name, number_of_establishments)

temp10 <- left_join(ppp_pop, biz_count, 
                              by = c("zip" = "geographic_area_name")) %>%
  drop_na(number_of_establishments) %>%
  mutate(businesses_per_pop = number_of_establishments / (estimate_total/10000)) %>%
  select(-number_of_establishments)

temp10 %>%
  summarize(n = n(), mean = mean(businesses_per_pop),
            sd = sd(businesses_per_pop))
```
```{r}

# Marital status descriptives

marital <- read_csv("raw_data/acs_marital/ACSST5Y2018.S1201_data_with_overlays_2020-10-19T152147.csv",
                    skip = 1) %>%
  clean_names() %>%
  select(geographic_area_name, estimate_now_married_except_separated_population_15_years_and_over) %>%
  mutate(geographic_area_name = map_chr(geographic_area_name, ~ substring(., 6)),
         geographic_area_name = str_trim(geographic_area_name, side = "both")) %>%
  rename("married_percent" = "estimate_now_married_except_separated_population_15_years_and_over")

temp11 <- left_join(loan_only, marital, 
                                      by = c("zip" = "geographic_area_name")) %>%
  drop_na(married_percent) %>%
  mutate(married_percent = as.double(married_percent)) %>%
  drop_na(married_percent)

temp11 %>%
  summarize(n = n(), mean = mean(married_percent),
            sd = sd(married_percent))
```


```{r}

# Adding in Gini coefficient

inequality <- read_csv('raw_data/acs_gini/ACSDT5Y2018.B19083_data_with_overlays_2020-10-26T225918.csv',
                       skip = 1) %>%
  clean_names() %>%
  select(geographic_area_name, estimate_gini_index) %>%
  mutate(estimate_gini_index = as.double(estimate_gini_index),
         geographic_area_name = 
           map_chr(geographic_area_name, ~ substring(., 6))) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

temp15 <- left_join(loan_only, inequality, 
                    by = c("zip" = "geographic_area_name")) %>%
  drop_na(estimate_gini_index)

temp15 %>%
  summarize(n = n(), mean = mean(estimate_gini_index),
            sd = sd(estimate_gini_index))
```


```{r}
# Adding in violent crime rates

crime <- read_excel('raw_data/county/county_health.xlsx', sheet = 'Ranked Measure Data',
                    skip = 1) %>%
  clean_names() %>%
  select(fips, annual_average_violent_crimes)

# Don't need to run this again if you have it above

county_zip_crosswalk <- read_excel('raw_data/crosswalks/COUNTY_ZIP_092020.xlsx') %>%
  clean_names() %>%
  select(county, zip, res_ratio)

# Weighting by population

crime_zip <- left_join(county_zip_crosswalk, crime, by = c("county" = "fips")) %>%
  mutate(annual_average_violent_crimes = annual_average_violent_crimes * res_ratio) %>%
  drop_na(annual_average_violent_crimes) %>%
  group_by(zip) %>%
  summarize(total_crime = sum(annual_average_violent_crimes), .groups = "drop")

temp16 <- left_join(ppp_pop, crime_zip, by = "zip") %>%
  mutate(violent_crime_rate = total_crime * 100000 / estimate_total) %>%
  drop_na(violent_crime_rate) %>%
  select(-total_crime)
  
temp16 %>% summarize(n = n(), mean = mean(violent_crime_rate), sd = sd(violent_crime_rate))
```


```{r}
# Calculating for business patterns -- payroll data

payroll <- 
  read_csv('raw_data/acs_business/ZBP2016.CB1600ZBP_data_with_overlays_2020-11-05T115551.csv',
           skip = 1) %>%
  clean_names() %>%
  filter(meaning_of_2012_naics_code == "Total for all sectors") %>%
  select(geographic_area_name, annual_payroll_1_000) %>%
  mutate(zip = str_sub(geographic_area_name, 5, 9),
         annual_payroll_1_000 = as.double(annual_payroll_1_000)) %>%
  rename("payroll" = "annual_payroll_1_000") %>%
  drop_na(payroll) %>%
  select(-geographic_area_name)

temp17 <- left_join(loan_only, payroll, by = "zip") %>%
  drop_na(payroll)

temp17 %>%
  summarize(n = n(), mean = mean(payroll), sd = sd(payroll))
```
```{r}
# Calculating lender characteristics via the dummy variables

loan_only %>%
    mutate(lender = tolower(lender)) %>%
    mutate(national = 0) %>%
    mutate(national = ifelse(str_detect(lender, pattern = "national association"),
                           1, national),
         national = ifelse(str_detect(lender, pattern = "n.a."),
                           1, national)) %>%
   mutate(cu = 0) %>%
   mutate(cu = ifelse(str_detect(lender, pattern = "\\sfcu$"), 1, 
                              cu),
         cu = ifelse(str_detect(lender, pattern = "\\scu$"), 1, 
                              cu),
         cu = ifelse(str_detect(lender, pattern = "credit union"), 1, 
                              cu)) %>%
  summarize(mean1 = mean(national), sd1 = sd(national),
            mean2 = mean(cu), sd2 = sd(cu))
```

```{r}

# Calculating gender ratios

gender <- 
  read_csv("raw_data/acs_race/ACSDP5Y2018.DP05_data_with_overlays_2020-10-12T162449.csv",
                skip = 1) %>%
  clean_names() %>%
  select(geographic_area_name, 
         percent_estimate_citizen_voting_age_population_citizen_18_and_over_population_male) %>%
  mutate(geographic_area_name = map_chr(geographic_area_name, ~ substring(., 6)),
         percent_estimate_citizen_voting_age_population_citizen_18_and_over_population_male = 
           as.double(percent_estimate_citizen_voting_age_population_citizen_18_and_over_population_male)) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))

temp17 <- left_join(loan_only, gender, 
                    by = c("zip" = "geographic_area_name")) %>%
  rename("male_percent" = 
           "percent_estimate_citizen_voting_age_population_citizen_18_and_over_population_male") %>%
  drop_na(male_percent) %>%
  summarize(n = n(), mean = mean(male_percent), sd = sd(male_percent))

```

```{r}
# Calculating renter percent

housing <- 
  read_csv('raw_data/acs_housing/ACSDP5Y2018.DP04_data_with_overlays_2020-11-20T172050.csv',
           skip = 1, col_types = cols()) %>%
  clean_names() %>%
  select(geographic_area_name,
         percent_estimate_housing_tenure_occupied_housing_units_renter_occupied) %>%
  rename("renter_percent" = 
           "percent_estimate_housing_tenure_occupied_housing_units_renter_occupied") %>%
  mutate(geographic_area_name = 
           map_chr(geographic_area_name, ~ substring(., 6))) %>%
  mutate(geographic_area_name = str_trim(geographic_area_name, side = "both"))


temp18 <- left_join(loan_only, housing, 
                                 by = c("zip" = "geographic_area_name")) %>%
  mutate(renter_percent = as.double(renter_percent)) %>%
  drop_na(renter_percent)

temp18 %>%
  summarize(mean = mean(renter_percent), sd = sd(renter_percent), 
            n = n())
```



```{r}

# This is code for remaking the full loan dataset like we did in file 1.
# I don't actually need this, since I saved the results to an RDS initially.

ppp_150 <- read_csv("raw_data/sba/PPP_SBA_150.csv") %>%
  clean_names() %>%
  select(loan_range, zip, date_approved, lender, address, city, state,
         jobs_reported) %>%
  drop_na(zip, jobs_reported) %>%
  
  # This calculates the date on which loans were approved vs. when apps opened.
  
  mutate(date_approved = mdy(date_approved), 
         days_to_approval = date_approved - mdy("04/03/2020"),
         zip = as.character(zip))

ppp_150_newcol <- ppp_150 %>%
  mutate(loan_amount = NA) %>%
  mutate(loan_amount = as.character(loan_amount))

sba_cleaning <- function(file) {
  x <- read_csv(file) %>%
    clean_names() %>%
    select(loan_amount, zip, date_approved, lender, city, state,
           jobs_reported) %>%
    drop_na(zip, jobs_reported) %>%
    mutate(date_approved = mdy(date_approved), 
         days_to_approval = date_approved - mdy("04/03/2020"),
         zip = as.character(zip))
}

# run for Mac

file.names1 <- 
  dir(path = "/Users/Regular/Desktop/GOV50/pppdata/raw_data/sba/states/", 
      pattern = ".csv")

# run for Windows

file.names2 <- 
  dir(path = "C:/Justin/Gov50/pppdata/raw_data/sba/states/", pattern = ".csv")

all_states<- tibble()

for(i in 1:length(file.names2)) {
  file <- sba_cleaning(paste("raw_data/sba/states/",file.names2[i], sep = ""))
  all_states <- rbind(all_states, file)
}

all_states2 <- all_states %>%
  mutate(loan_range = "less than 150k", address = NA)

ppp_total <- rbind(ppp_150_newcol, all_states2)

ppp_total %>%
  drop_na(jobs_reported) %>%
  summarize(n = n(), mean = mean(jobs_reported), sd = sd(jobs_reported))


```



